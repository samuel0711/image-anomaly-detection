{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "con_tcc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOe1y29hwKHAfDXZnwn5rjQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuel0711/image-anomaly-detection/blob/main/con_tcc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSYuFnl5CR4n",
        "outputId": "ab8d7034-8dc1-460b-fcce-10feb45a70bd"
      },
      "source": [
        "import io\n",
        "import sys\n",
        "import os\n",
        "import gc\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io as skio\n",
        "import torch\n",
        "from torch import nn #neural networks\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "#Carregamento de Dados\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    os.chdir(\"/content/drive/My Drive/Colab Notebooks\")\n",
        "    sys.path.append('/content/drive/My Drive/Colab Notebooks')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYAT-KAsB42R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ca1515-13d5-4848-e16b-b23502b1ea7c"
      },
      "source": [
        "args = {\n",
        "    'epoch':50,          #Numero de épocas\n",
        "    'lr':1e-5,            #Taxa de aprendizado\n",
        "    'weight_decay':5e-3,  #Penalidade L2 (Regularização)\n",
        "    'batch_size': 50,     #Tamanho do batch\n",
        "    'num_workers': 4\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  args['device'] = torch.device('cuda')\n",
        "else:\n",
        "  args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])\n",
        "\n",
        "\n",
        "train_set = np.load('train_dataset.npy', allow_pickle = True)\n",
        "test_set = np.load('test_dataset.npy', allow_pickle = True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Treino\\nMédia: ',train_set.mean(),'\\t Desvio Padrão: ',train_set.std(),'\\n\\n')\n",
        "print('Teste\\nMédia: ',test_set.mean(),'\\t Desvio Padrão: ',test_set.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj4IxvZ5BC-8",
        "outputId": "7e31962e-4e9f-4c40-e905-25bd04964f02"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino\n",
            "Média:  105.99875310358665 \t Desvio Padrão:  48.06406962223618 \n",
            "\n",
            "\n",
            "Teste\n",
            "Média:  112.34485052083333 \t Desvio Padrão:  45.537924097632626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torch.from_numpy(train_set)\n",
        "\n",
        "test_set = torch.from_numpy(test_set)"
      ],
      "metadata": {
        "id": "iXr6tMUp0c_U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.Normalize((train_set.mean(), ), (train_set.std(), ))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Normalize((test_set.mean(), ), (test_set.std(), ))\n",
        "])\n",
        "  \n",
        "# image\n",
        "train_set = transform_train(train_set)#.permute(1,2,0)\n",
        "test_set = transform_test(test_set)#.permute(1,2,0)"
      ],
      "metadata": {
        "id": "z1eefBaUuSuT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJiOOTaxmimJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8947cf6-4a7b-43b8-889a-7f3305db891b"
      },
      "source": [
        "train_loader = DataLoader(train_set, \n",
        "                          batch_size=args['batch_size'], \n",
        "                          shuffle=True, \n",
        "                          num_workers=args['num_workers'])\n",
        "\n",
        "test_loader = DataLoader(test_set, \n",
        "                         batch_size=args['batch_size'], \n",
        "                         shuffle=True, \n",
        "                         num_workers=args['num_workers']) "
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the Convolutional Autoencoder\n",
        "class ConvAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvAutoencoder, self).__init__()\n",
        "       \n",
        "        #Encoder\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding = 1)  #in_channel, out_channel, kernel_size\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding = 1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding = 1) \n",
        "        self.pool = nn.MaxPool2d(2, 2) #kernel_size, stride\n",
        "       \n",
        "        #Decoder\n",
        "        self.t_conv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.t_conv2 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
        "        self.t_conv3 = nn.ConvTranspose2d(32, 1, 2, stride=2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.t_conv1(x))\n",
        "        x = F.relu(self.t_conv2(x))\n",
        "        x = torch.sigmoid(self.t_conv3(x))\n",
        "              \n",
        "        return x\n",
        "\n",
        "\n",
        "#Instantiate the model\n",
        "model = ConvAutoencoder()\n"
      ],
      "metadata": {
        "id": "Es1OH4QXblsC"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQhg2NBR46DB"
      },
      "source": [
        "# **Treinando**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-c6HSrSzJ1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a24580-ec17-42cd-c2a7-513732b7d8cd"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "criterio = nn.MSELoss().to(args['device'])\n",
        "optimizer = optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
        "model.to(args['device'])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvAutoencoder(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=5, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (t_conv1): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2))\n",
              "  (t_conv2): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2))\n",
              "  (t_conv3): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(2, 2))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_decod_img(img, output, epoch, name):\n",
        "    img = img.view(img.size(0), 1, 120, 120)\n",
        "    output = output.view(output.size(0), 1, 120, 120)\n",
        "    error = output.view(output.size(0), 1, 120, 120) - img.view(img.size(0), 1, 120, 120)\n",
        "    save_image(img, './imgs_tcc/{}_imagem_image{}.png'.format(name,epoch))\n",
        "    save_image(output, './imgs_tcc/{}_output_image{}.png'.format(name,epoch))\n",
        "    save_image(error, './imgs_tcc/{}_error_image{}.png'.format(name,epoch))"
      ],
      "metadata": {
        "id": "_s9WKltZrPdU"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treino ( Somente com imagens não-anomalas)"
      ],
      "metadata": {
        "id": "vMrPLQr4hvrE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GemLuqJp7aIL"
      },
      "source": [
        "def train(train_loader, model, epoch, name):\n",
        "  ###################\n",
        "  # treinando o modelo #\n",
        "  ###################\n",
        "  model.train()\n",
        "  \n",
        "  start = time.time()\n",
        "\n",
        "  train_loss = 0.0\n",
        "  for data in train_loader:\n",
        "    imagem = data.unsqueeze(1).float()\n",
        "    imagem = imagem.to(args['device'])\n",
        "\n",
        "    # clear the gradients of all optimized variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = model(imagem)\n",
        "\n",
        "    # calculando loss\n",
        "    loss = criterio(output, imagem)\n",
        "\n",
        "    # backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # próximo passo\n",
        "    optimizer.step()\n",
        "\n",
        "    # update running training loss\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    save_decod_img(imagem.cpu().data, output.cpu().data, epoch, name)\n",
        "\n",
        "\n",
        "  train_loss = train_loss/len(train_loader)\n",
        "\n",
        "  end = time.time()\n",
        "\n",
        "\n",
        "  print('########## Train ##########')\n",
        "\n",
        "  print(\"Epoca: {}\\t Train Loss: {:.3f}, Time: {:.2f}\\n\".format(epoch, train_loss, end-start))\n",
        "  #print(\"Medía do Loss:\", epoch_loss_train.mean())\n",
        "\n",
        "  return train_loss"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste ( Somente com imagens anômalas )"
      ],
      "metadata": {
        "id": "4SqIE-syh4Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(test_loader, model, epoch, name):\n",
        "  ###################\n",
        "  # validando o modelo #\n",
        "  ###################\n",
        "  model.eval()\n",
        "  \n",
        "  start = time.time()\n",
        "  \n",
        "  test_loss = 0.0\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      imagem = data.unsqueeze(1).float()\n",
        "      imagem = imagem.to(args['device'])\n",
        "\n",
        "      # forward pass\n",
        "      output = model(imagem)\n",
        "\n",
        "      # calculando loss\n",
        "      loss = criterio(output, imagem)\n",
        "\n",
        "      # update running test loss\n",
        "      test_loss += loss.item()\n",
        "\n",
        "    test_loss = test_loss/len(test_loader)\n",
        "    end = time.time()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "      save_decod_img(imagem.cpu().data, output.cpu().data, epoch, name)\n",
        "    print('########## Test ##########')\n",
        "    \n",
        "    print(\"Epoca: {}\\t Test Loss: {:.3f}, Time: {:.2f}\\n\".format(epoch, test_loss, end-start))\n",
        "\n",
        "    return test_loss"
      ],
      "metadata": {
        "id": "991BeROg8xf3"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rodando Teste e Treino"
      ],
      "metadata": {
        "id": "6eTPY7xYolud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, test_losses = [], []\n",
        "\n",
        "for epoch in range(args['epoch']):\n",
        "  #Train\n",
        "  train_losses.append(train(train_loader, model, epoch, 'train'))\n",
        "  test_losses.append(validate(test_loader, model, epoch, 'test'))"
      ],
      "metadata": {
        "id": "X16XessjolJa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "7fe06124-5ac0-4210-de6d-6ef3600196da"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([50, 1, 120, 120])) that is different to the input size (torch.Size([50, 1, 103, 103])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-1beff7c071fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m#Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-8fe9c797cc5d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, epoch, name)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# calculando loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimagem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3109\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3111\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (103) must match the size of tensor b (120) at non-singleton dimension 3"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Treino x Teste"
      ],
      "metadata": {
        "id": "0rXPlSNFijQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " plt.plot(train_losses, label='Train')\n",
        " plt.plot(test_losses, label='Test')\n",
        " plt.legend(loc=\"upper right\")\n",
        " plt.ylabel('Loss')\n",
        " plt.xlabel('Epochs')"
      ],
      "metadata": {
        "id": "nUMrkYR5iiqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot da Imagem Original(normalizada) x Imagem Reconstruída via AutoEncoder Convolucional"
      ],
      "metadata": {
        "id": "AHoIUvBmirI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain one batch of test images\n",
        "dataiter = iter(train_loader)\n",
        "images = dataiter.next()\n",
        "\n",
        "imagem = images.unsqueeze(1).float()\n",
        "imagem /= 255.0\n",
        "imagem = imagem.to(args['device'])\n",
        "\n",
        "# get sample outputs\n",
        "output = model(imagem)\n",
        "# prep images for display\n",
        "images = images.numpy()\n",
        "\n",
        "\n",
        "\n",
        "# output is resized into a batch of iages\n",
        "output = output.view(args['batch_size'], 1, 160, 240)\n",
        "# use detach when it's an output that requires_grad\n",
        "output = output.detach()#.numpy()\n",
        "\n",
        "\n",
        "\n",
        "# plot the first ten input images and then reconstructed images\n",
        "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    loss = criterio(output[idx], imagem[idx])\n",
        "    label = 'Loss value: {:.3f}'\n",
        "    ax.set_xlabel(label.format(loss) )\n",
        "    ax.set_title(\"Reconstructed Image\")\n",
        "    plt.imshow(output[idx].squeeze().cpu(), cmap='gray')\n",
        "    \n",
        "# plot the first ten input images and then reconstructed images\n",
        "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    loss = criterio(output[idx], imagem[idx])\n",
        "    label = 'Loss value: {:.3f}'\n",
        "    ax.set_xlabel(label.format(loss) )\n",
        "    ax.set_title(\"Original Image\")\n",
        "    plt.imshow(images[idx].squeeze(), cmap='gray')\n"
      ],
      "metadata": {
        "id": "CNOb9zHIiohP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogQCkTYUE9cY"
      },
      "source": [
        "# obtain one batch of test images\n",
        "dataiter = iter(test_loader)\n",
        "images = dataiter.next()\n",
        "\n",
        "imagem = images.unsqueeze(1).float()\n",
        "imagem /= 255.0\n",
        "imagem = imagem.to(args['device'])\n",
        "\n",
        "# get sample outputs\n",
        "output = model(imagem)\n",
        "# prep images for display\n",
        "images = images.numpy()\n",
        "\n",
        "\n",
        "\n",
        "# output is resized into a batch of iages\n",
        "output = output.view(args['batch_size'], 1, 160, 240)\n",
        "# use detach when it's an output that requires_grad\n",
        "output = output.detach()#.numpy()\n",
        "\n",
        "\n",
        "\n",
        "# plot the first ten input images and then reconstructed images\n",
        "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    loss = criterio(output[idx], imagem[idx])\n",
        "    label = 'Loss value: {:.3f}'\n",
        "    ax.set_xlabel(label.format(loss) )\n",
        "    ax.set_title(\"Reconstructed Image\")\n",
        "    plt.imshow(output[idx].squeeze().cpu(), cmap='gray')\n",
        "    \n",
        "# plot the first ten input images and then reconstructed images\n",
        "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    loss = criterio(output[idx], imagem[idx])\n",
        "    label = 'Loss value: {:.3f}'\n",
        "    ax.set_xlabel(label.format(loss) )\n",
        "    ax.set_title(\"Original Image\")\n",
        "    plt.imshow(images[idx].squeeze(), cmap='gray')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
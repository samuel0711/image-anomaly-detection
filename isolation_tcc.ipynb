{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuel0711/image-anomaly-detection/blob/main/isolation_tcc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSYuFnl5CR4n",
        "outputId": "6dc772ef-7ae5-4479-85e9-ba8e3600d36b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import sys\n",
        "import os\n",
        "import gc\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io as skio\n",
        "import torch\n",
        "from torch import nn #neural networks\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "#Carregamento de Dados\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    os.chdir(\"/content/drive/My Drive/Colab Notebooks\")\n",
        "    sys.path.append('/content/drive/My Drive/Colab Notebooks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYAT-KAsB42R",
        "outputId": "d17299d5-92d5-416e-bd71-f74742947d58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "args = {\n",
        "    'epoch':100,          #Numero de épocas\n",
        "    'lr':1e-4,            #Taxa de aprendizado\n",
        "    'weight_decay':5e-5,  #Penalidade L2 (Regularização)\n",
        "    'batch_size': 50,     #Tamanho do batch\n",
        "    'num_workers': 2\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  args['device'] = torch.device('cuda')\n",
        "else:\n",
        "  args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])\n",
        "\n",
        "\n",
        "train_set = np.load('train_dataset.npy', allow_pickle = True)/255.0\n",
        "test_set = np.load('test_dataset.npy', allow_pickle = True)/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj4IxvZ5BC-8",
        "outputId": "7253f616-f0a6-44bc-d0da-9de2214fed1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:212: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino\n",
            "Média:  0.3945 \t Desvio Padrão:  inf \n",
            "\n",
            "\n",
            "Teste\n",
            "Média:  0.44 \t Desvio Padrão:  inf\n"
          ]
        }
      ],
      "source": [
        "print('Treino\\nMédia: ',train_set.mean(),'\\t Desvio Padrão: ',train_set.std(),'\\n\\n')\n",
        "print('Teste\\nMédia: ',test_set.mean(),'\\t Desvio Padrão: ',test_set.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "iXr6tMUp0c_U"
      },
      "outputs": [],
      "source": [
        "train_set = torch.from_numpy(train_set)\n",
        "test_set = torch.from_numpy(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "u3WOjrbee9wN"
      },
      "outputs": [],
      "source": [
        "#dataset = np.concatenate((train_set, test_set))\n",
        "\n",
        "#dataset = np.reshape(dataset,(dataset.shape[0], dataset.shape[1]*dataset.shape[2]))\n",
        "\n",
        "#isolation_forest.fit(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "z1eefBaUuSuT",
        "outputId": "d95c3905-73a9-4f65-b2f0-5dff5938db0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'transform_train = transforms.Compose([\\n    transforms.Normalize((train_set.mean(), ), (train_set.std(), ))\\n])\\n\\ntransform_test = transforms.Compose([\\n    transforms.Normalize((test_set.mean(), ), (test_set.std(), ))\\n])\\n  \\n# image\\ntrain_set = transform_train(train_set)#.permute(1,2,0)\\ntest_set = transform_test(test_set)#.permute(1,2,0)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "'''transform_train = transforms.Compose([\n",
        "    transforms.Normalize((train_set.mean(), ), (train_set.std(), ))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Normalize((test_set.mean(), ), (test_set.std(), ))\n",
        "])\n",
        "  \n",
        "# image\n",
        "train_set = transform_train(train_set)#.permute(1,2,0)\n",
        "test_set = transform_test(test_set)#.permute(1,2,0)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "rJiOOTaxmimJ"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, \n",
        "                          batch_size=args['batch_size'], \n",
        "                          shuffle=True, \n",
        "                          num_workers=args['num_workers'])\n",
        "\n",
        "test_loader = DataLoader(test_set, \n",
        "                         batch_size=args['batch_size'], \n",
        "                         shuffle=True, \n",
        "                         num_workers=args['num_workers']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Es1OH4QXblsC"
      },
      "outputs": [],
      "source": [
        "#Define the Convolutional Autoencoder\n",
        "class ConvAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvAutoencoder, self).__init__()\n",
        "       \n",
        "        #Encoder\n",
        "        self.conv1 = nn.Conv2d(1, 64, 3, padding = 1)  #in_channel, out_channel, kernel_size\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding = 1)\n",
        "        self.conv3 = nn.Conv2d(128, 128, 3, padding = 1) \n",
        "        self.conv4 = nn.Conv2d(128, 254, 3, padding = 1) \n",
        "        self.pool = nn.MaxPool2d(2) #kernel_size, stride\n",
        "       \n",
        "        #Decoder\n",
        "        self.t_conv1 = nn.ConvTranspose2d(254, 128, 2, stride=2)        \n",
        "        self.t_conv2 = nn.ConvTranspose2d(128, 128, 2, stride=2)\n",
        "        self.t_conv3 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.t_conv4 = nn.ConvTranspose2d(64, 1, 2, stride=2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.leaky_relu(self.conv4(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.t_conv1(x))\n",
        "        x = F.relu(self.t_conv2(x))\n",
        "        x = F.relu(self.t_conv3(x))\n",
        "        x = torch.sigmoid(self.t_conv4(x))\n",
        "              \n",
        "        return x\n",
        "\n",
        "\n",
        "#Instantiate the model\n",
        "model = ConvAutoencoder()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQhg2NBR46DB"
      },
      "source": [
        "# **Treinando**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-c6HSrSzJ1V",
        "outputId": "9884c54d-77c7-44ec-a1b9-bf6c9a31df5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvAutoencoder(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(128, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (t_conv1): ConvTranspose2d(254, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (t_conv2): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (t_conv3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (t_conv4): ConvTranspose2d(64, 1, kernel_size=(2, 2), stride=(2, 2))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "from torch import optim\n",
        "\n",
        "criterio = nn.MSELoss().to(args['device'])\n",
        "optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
        "model.to(args['device'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "_s9WKltZrPdU"
      },
      "outputs": [],
      "source": [
        "def save_decod_img(img, output, epoch, name):\n",
        "    img = img.view(img.size(0), 1, img.shape[2], img.shape[3])\n",
        "    output = output.view(output.size(0), 1, output.shape[2], output.shape[3])\n",
        "    error = output.view(output.size(0), 1, output.shape[2], output.shape[3]) - img.view(img.size(0), 1, img.shape[2], img.shape[3])\n",
        "    save_image(img, './imgs_tcc/{}_imagem_image{}.png'.format(name,epoch))\n",
        "    save_image(output, './imgs_tcc/{}_output_image{}.png'.format(name,epoch))\n",
        "    save_image(error, './imgs_tcc/{}_error_image{}.png'.format(name,epoch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMrPLQr4hvrE"
      },
      "source": [
        "## Treino ( Somente com imagens não-anomalas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "GemLuqJp7aIL"
      },
      "outputs": [],
      "source": [
        "def train(train_loader, model, epoch, name):\n",
        "  ###################\n",
        "  # treinando o modelo #\n",
        "  ###################\n",
        "  model.train()\n",
        "  \n",
        "  start = time.time()\n",
        "\n",
        "  tns = []\n",
        "\n",
        "  train_loss = 0.0\n",
        "  for data in train_loader:\n",
        "    imagem = data.unsqueeze(1).float()\n",
        "    imagem = imagem.to(args['device'])\n",
        "\n",
        "    #imagem = imagem/255.0\n",
        "\n",
        "    # clear the gradients of all optimized variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = model(imagem)\n",
        "\n",
        "    # calculando loss\n",
        "    loss = criterio(output, imagem)\n",
        "    #isolation_forest.fit(torch.flatten(output,start_dim=1).cpu().data)\n",
        "\n",
        "\n",
        "    # backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # próximo passo\n",
        "    optimizer.step()\n",
        "\n",
        "    # update running training loss\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    if epoch == args['epoch']:\n",
        "      for x, y in zip(imagem, output):\n",
        "          tns.append(np.array(y.squeeze().cpu().data - x.squeeze().cpu().data))\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    save_decod_img(imagem.cpu().data, output.cpu().data, epoch, name)\n",
        "\n",
        "\n",
        "  train_loss = train_loss/len(train_loader)\n",
        "\n",
        "  end = time.time()\n",
        "\n",
        "\n",
        "  print('########## Train ##########')\n",
        "\n",
        "  print(\"Epoca: {}\\t Train Loss: {:.6f}, Time: {:.2f}\\n\".format(epoch, train_loss, end-start))\n",
        "  #print(\"Medía do Loss:\", epoch_loss_train.mean())\n",
        "\n",
        "  return train_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SqIE-syh4Dm"
      },
      "source": [
        "## Validação ( Somente com imagens anômalas )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "991BeROg8xf3"
      },
      "outputs": [],
      "source": [
        "def validate(test_loader, model, epoch, name):\n",
        "  ###################\n",
        "  # validando o modelo #\n",
        "  ###################\n",
        "  model.eval()\n",
        "\n",
        "  tns = []\n",
        "  predicts = []\n",
        "  outliers, inliers = 0, 0\n",
        "  \n",
        "  start = time.time()\n",
        "  \n",
        "  test_loss = 0.0\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      imagem = data.unsqueeze(1).float()\n",
        "      imagem = imagem.to(args['device'])\n",
        "\n",
        "      #imagem = imagem/255.0\n",
        "      # forward pass\n",
        "      output = model(imagem)\n",
        "\n",
        "      #y = isolation_forest.predict(torch.flatten(output,start_dim=1).cpu().data)\n",
        "      #outliers += list(y).count(-1)\n",
        "      #inliers += list(y).count(1)\n",
        "      #predicts.append(list(y).count(-1)/y.shape[0])\n",
        "\n",
        "      # calculando loss\n",
        "      loss = criterio(output, imagem)\n",
        "\n",
        "      # update running test loss\n",
        "      test_loss += loss.item()\n",
        "\n",
        "      if epoch == (args['epoch']-1):\n",
        "        for x, y in zip(imagem, output):\n",
        "          tns.append(y.squeeze().cpu().numpy() - x.squeeze().cpu().numpy())\n",
        "\n",
        "    test_loss = test_loss/len(test_loader)\n",
        "    end = time.time()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "      save_decod_img(imagem.cpu().data, output.cpu().data, epoch, name)\n",
        "    print('########## Validate ##########')\n",
        "\n",
        "    \n",
        "    print(\"Epoca: {}\\t Val Loss: {:.6f}, Time: {:.2f}\\n\".format(epoch, test_loss, end-start)) #\\nAcurácia do Isolation Forest: {:.3f}\\t {} Outliers, {} Inliers\\n\".format(epoch, test_loss, end-start, (sum(predicts)/len(predicts)), outliers, inliers))\n",
        "\n",
        "    return test_loss#, (sum(predicts)/len(predicts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eTPY7xYolud"
      },
      "source": [
        "## Rodando Validação e Treino\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X16XessjolJa",
        "outputId": "f5c58432-77a1-4849-b7a4-aa2e90d01b30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########## Train ##########\n",
            "Epoca: 0\t Train Loss: 0.027106, Time: 19.09\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 0\t Val Loss: 0.006026, Time: 2.00\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 1\t Train Loss: 0.005342, Time: 18.02\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 1\t Val Loss: 0.004186, Time: 1.99\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 2\t Train Loss: 0.004089, Time: 18.17\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 2\t Val Loss: 0.003700, Time: 2.01\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 3\t Train Loss: 0.003432, Time: 18.38\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 3\t Val Loss: 0.003358, Time: 2.01\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 4\t Train Loss: 0.003008, Time: 18.47\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 4\t Val Loss: 0.003105, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 5\t Train Loss: 0.002688, Time: 19.77\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 5\t Val Loss: 0.002914, Time: 2.02\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 6\t Train Loss: 0.002442, Time: 18.68\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 6\t Val Loss: 0.002708, Time: 2.02\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 7\t Train Loss: 0.002243, Time: 18.74\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 7\t Val Loss: 0.002578, Time: 2.02\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 8\t Train Loss: 0.002082, Time: 18.83\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 8\t Val Loss: 0.002451, Time: 2.02\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 9\t Train Loss: 0.001944, Time: 18.87\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 9\t Val Loss: 0.002358, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 10\t Train Loss: 0.001834, Time: 20.09\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 10\t Val Loss: 0.002294, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 11\t Train Loss: 0.001739, Time: 18.95\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 11\t Val Loss: 0.002208, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 12\t Train Loss: 0.001661, Time: 18.99\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 12\t Val Loss: 0.002147, Time: 2.06\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 13\t Train Loss: 0.001593, Time: 19.02\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 13\t Val Loss: 0.002097, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 14\t Train Loss: 0.001531, Time: 19.03\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 14\t Val Loss: 0.002040, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 15\t Train Loss: 0.001480, Time: 20.21\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 15\t Val Loss: 0.002019, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 16\t Train Loss: 0.001431, Time: 19.05\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 16\t Val Loss: 0.001960, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 17\t Train Loss: 0.001392, Time: 19.08\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 17\t Val Loss: 0.001923, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 18\t Train Loss: 0.001353, Time: 19.09\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 18\t Val Loss: 0.001893, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 19\t Train Loss: 0.001320, Time: 19.11\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 19\t Val Loss: 0.001869, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 20\t Train Loss: 0.001290, Time: 20.31\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 20\t Val Loss: 0.001841, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 21\t Train Loss: 0.001262, Time: 19.08\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 21\t Val Loss: 0.001828, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 22\t Train Loss: 0.001236, Time: 19.11\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 22\t Val Loss: 0.001798, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 23\t Train Loss: 0.001214, Time: 19.11\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 23\t Val Loss: 0.001763, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 24\t Train Loss: 0.001193, Time: 19.14\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 24\t Val Loss: 0.001753, Time: 2.06\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 25\t Train Loss: 0.001171, Time: 20.32\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 25\t Val Loss: 0.001745, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 26\t Train Loss: 0.001154, Time: 19.10\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 26\t Val Loss: 0.001718, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 27\t Train Loss: 0.001137, Time: 19.08\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 27\t Val Loss: 0.001697, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 28\t Train Loss: 0.001118, Time: 19.07\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 28\t Val Loss: 0.001726, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 29\t Train Loss: 0.001105, Time: 19.08\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 29\t Val Loss: 0.001677, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 30\t Train Loss: 0.001089, Time: 20.29\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 30\t Val Loss: 0.001670, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 31\t Train Loss: 0.001073, Time: 19.10\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 31\t Val Loss: 0.001637, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 32\t Train Loss: 0.001062, Time: 19.10\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 32\t Val Loss: 0.001631, Time: 2.02\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 33\t Train Loss: 0.001050, Time: 19.10\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 33\t Val Loss: 0.001611, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 34\t Train Loss: 0.001037, Time: 19.11\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 34\t Val Loss: 0.001599, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 35\t Train Loss: 0.001027, Time: 20.32\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 35\t Val Loss: 0.001593, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 36\t Train Loss: 0.001016, Time: 19.08\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 36\t Val Loss: 0.001584, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 37\t Train Loss: 0.001006, Time: 19.19\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 37\t Val Loss: 0.001571, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 38\t Train Loss: 0.000998, Time: 19.11\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 38\t Val Loss: 0.001574, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 39\t Train Loss: 0.000989, Time: 19.11\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 39\t Val Loss: 0.001549, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 40\t Train Loss: 0.000977, Time: 20.30\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 40\t Val Loss: 0.001550, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 41\t Train Loss: 0.000970, Time: 19.10\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 41\t Val Loss: 0.001551, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 42\t Train Loss: 0.000963, Time: 19.13\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 42\t Val Loss: 0.001529, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 43\t Train Loss: 0.000955, Time: 19.14\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 43\t Val Loss: 0.001532, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 44\t Train Loss: 0.000947, Time: 19.11\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 44\t Val Loss: 0.001516, Time: 2.02\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 45\t Train Loss: 0.000940, Time: 20.30\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 45\t Val Loss: 0.001514, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 46\t Train Loss: 0.000933, Time: 19.10\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 46\t Val Loss: 0.001503, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 47\t Train Loss: 0.000926, Time: 19.12\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 47\t Val Loss: 0.001488, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 48\t Train Loss: 0.000919, Time: 19.14\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 48\t Val Loss: 0.001488, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 49\t Train Loss: 0.000912, Time: 19.24\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 49\t Val Loss: 0.001487, Time: 2.07\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 50\t Train Loss: 0.000907, Time: 20.34\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 50\t Val Loss: 0.001481, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 51\t Train Loss: 0.000901, Time: 19.15\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 51\t Val Loss: 0.001466, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 52\t Train Loss: 0.000894, Time: 19.19\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 52\t Val Loss: 0.001469, Time: 2.06\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 53\t Train Loss: 0.000890, Time: 19.19\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 53\t Val Loss: 0.001470, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 54\t Train Loss: 0.000885, Time: 19.15\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 54\t Val Loss: 0.001450, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 55\t Train Loss: 0.000877, Time: 20.36\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 55\t Val Loss: 0.001446, Time: 2.06\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 56\t Train Loss: 0.000874, Time: 19.19\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 56\t Val Loss: 0.001446, Time: 2.07\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 57\t Train Loss: 0.000868, Time: 19.19\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 57\t Val Loss: 0.001431, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 58\t Train Loss: 0.000864, Time: 19.13\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 58\t Val Loss: 0.001431, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 59\t Train Loss: 0.000860, Time: 19.14\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 59\t Val Loss: 0.001427, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 60\t Train Loss: 0.000855, Time: 20.31\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 60\t Val Loss: 0.001429, Time: 2.02\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 61\t Train Loss: 0.000849, Time: 19.13\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 61\t Val Loss: 0.001412, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 62\t Train Loss: 0.000845, Time: 19.15\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 62\t Val Loss: 0.001418, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 63\t Train Loss: 0.000843, Time: 19.15\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 63\t Val Loss: 0.001410, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 64\t Train Loss: 0.000837, Time: 19.17\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 64\t Val Loss: 0.001413, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 65\t Train Loss: 0.000833, Time: 20.30\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 65\t Val Loss: 0.001397, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 66\t Train Loss: 0.000831, Time: 19.14\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 66\t Val Loss: 0.001395, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 67\t Train Loss: 0.000824, Time: 19.14\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 67\t Val Loss: 0.001392, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 68\t Train Loss: 0.000821, Time: 19.18\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 68\t Val Loss: 0.001391, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 69\t Train Loss: 0.000818, Time: 19.16\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 69\t Val Loss: 0.001387, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 70\t Train Loss: 0.000813, Time: 20.33\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 70\t Val Loss: 0.001385, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 71\t Train Loss: 0.000810, Time: 19.14\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 71\t Val Loss: 0.001371, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 72\t Train Loss: 0.000806, Time: 19.15\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 72\t Val Loss: 0.001373, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 73\t Train Loss: 0.000805, Time: 19.15\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 73\t Val Loss: 0.001366, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 74\t Train Loss: 0.000800, Time: 19.18\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 74\t Val Loss: 0.001363, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 75\t Train Loss: 0.000798, Time: 20.32\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 75\t Val Loss: 0.001358, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 76\t Train Loss: 0.000793, Time: 19.13\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 76\t Val Loss: 0.001358, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 77\t Train Loss: 0.000789, Time: 19.14\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 77\t Val Loss: 0.001354, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 78\t Train Loss: 0.000786, Time: 19.19\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 78\t Val Loss: 0.001362, Time: 2.03\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 79\t Train Loss: 0.000784, Time: 19.16\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 79\t Val Loss: 0.001353, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 80\t Train Loss: 0.000782, Time: 20.34\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 80\t Val Loss: 0.001346, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 81\t Train Loss: 0.000777, Time: 19.14\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 81\t Val Loss: 0.001341, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 82\t Train Loss: 0.000776, Time: 19.15\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 82\t Val Loss: 0.001336, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 83\t Train Loss: 0.000773, Time: 19.17\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 83\t Val Loss: 0.001343, Time: 2.06\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 84\t Train Loss: 0.000770, Time: 19.18\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 84\t Val Loss: 0.001340, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 85\t Train Loss: 0.000766, Time: 20.34\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 85\t Val Loss: 0.001330, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 86\t Train Loss: 0.000763, Time: 19.14\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 86\t Val Loss: 0.001323, Time: 2.06\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 87\t Train Loss: 0.000761, Time: 19.16\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 87\t Val Loss: 0.001321, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 88\t Train Loss: 0.000760, Time: 19.17\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 88\t Val Loss: 0.001320, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 89\t Train Loss: 0.000757, Time: 19.20\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 89\t Val Loss: 0.001331, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 90\t Train Loss: 0.000751, Time: 20.35\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 90\t Val Loss: 0.001316, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 91\t Train Loss: 0.000751, Time: 19.16\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 91\t Val Loss: 0.001312, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 92\t Train Loss: 0.000748, Time: 19.15\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 92\t Val Loss: 0.001314, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 93\t Train Loss: 0.000747, Time: 19.19\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 93\t Val Loss: 0.001320, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 94\t Train Loss: 0.000743, Time: 19.18\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 94\t Val Loss: 0.001306, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 95\t Train Loss: 0.000739, Time: 20.35\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 95\t Val Loss: 0.001318, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 96\t Train Loss: 0.000742, Time: 19.18\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 96\t Val Loss: 0.001296, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 97\t Train Loss: 0.000734, Time: 19.19\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 97\t Val Loss: 0.001309, Time: 2.04\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 98\t Train Loss: 0.000737, Time: 19.18\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 98\t Val Loss: 0.001299, Time: 2.05\n",
            "\n",
            "########## Train ##########\n",
            "Epoca: 99\t Train Loss: 0.000732, Time: 19.20\n",
            "\n",
            "########## Validate ##########\n",
            "Epoca: 99\t Val Loss: 0.001292, Time: 2.42\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_losses, val_losses = [], []\n",
        "val_predicts = []\n",
        "\n",
        "i = 1\n",
        "for epoch in range(args['epoch']):\n",
        "  #Train\n",
        "  train_loss = train(train_loader, model, epoch, 'train')\n",
        "  train_losses.append(train_loss)\n",
        "\n",
        "  val_loss = validate(test_loader, model, epoch, 'test')\n",
        "  val_losses.append(val_loss)\n",
        "  #val_predicts.append(predicts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSLDlucDFZ5M"
      },
      "source": [
        "## Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "kvt5EhM4FfDF"
      },
      "outputs": [],
      "source": [
        "train_label = np.zeros(train_set.shape[0])\n",
        "test_label = np.ones(test_set.shape[0])\n",
        "\n",
        "labels = np.concatenate((train_label, test_label))\n",
        "dataset = np.concatenate((train_set, test_set))\n",
        "\n",
        "#data_fit = np.reshape(data, (data.shape[0],data.shape[1]*data.shape[2]))\n",
        "\n",
        "labels = torch.from_numpy(labels)\n",
        "dataset = torch.from_numpy(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "NAvla2_1IrYQ"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader([ [dataset[i], labels[i]] for i in range(len(dataset))],\n",
        "                        shuffle=True,\n",
        "                        batch_size=args['batch_size'],\n",
        "                        num_workers=args['num_workers'])\n",
        "\n",
        "isolation_forest = IsolationForest(n_estimators = 20, contamination = 0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "tns = []\n",
        "\n",
        "for x in dataloader:\n",
        "  imagem, _ = x\n",
        "  imagem = imagem.unsqueeze(1).float()\n",
        "  imagem = imagem.to(args['device'])\n",
        "\n",
        "  # forward pass\n",
        "  output = model(imagem)\n",
        "\n",
        "  #isolation_forest.fit(torch.flatten(output,start_dim=1).cpu().data)\n",
        "\n",
        "  # calculando loss\n",
        "  loss = criterio(output, imagem)\n",
        "\n",
        "  for img in output:\n",
        "    tns.append(img.squeeze().cpu().data.numpy())\n",
        "\n",
        "\n",
        "print(\"Loss: \",loss.item())"
      ],
      "metadata": {
        "id": "69aXv3N6FpBx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc20ae97-939b-47b6-80e8-c2309aeb87cf"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  0.0008035774808377028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "isolation_dataset = np.array(tns)\n",
        "\n",
        "isolation_dataset = np.reshape(isolation_dataset, (isolation_dataset.shape[0],isolation_dataset.shape[1]*isolation_dataset.shape[2]))\n",
        "\n",
        "isolation_forest.fit(isolation_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqozyBhV9p68",
        "outputId": "84448b90-ed61-456b-9375-09c13301c5b9"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IsolationForest(contamination=0.2, n_estimators=20)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "3CAobTgLFe3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15364e0-7e49-47a1-bcba-c3effe09469e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########## Test ##########\n",
            "Test Loss: 0.004199\n",
            "Acurácia do Isolation Forest: 0.113\t 2000 Outliers, 8000 Inliers\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "tns = []\n",
        "predicts = []\n",
        "outliers, inliers = 0, 0\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "  for data in dataloader:\n",
        "    imagem, label = data\n",
        "    imagem = imagem.unsqueeze(1).float()\n",
        "    imagem = imagem.to(args['device'])\n",
        "\n",
        "    # forward pass\n",
        "    output = model(imagem)\n",
        "\n",
        "    y = isolation_forest.predict(torch.flatten(output,start_dim=1).cpu().data)\n",
        "    outliers += list(y).count(-1)\n",
        "    inliers += list(y).count(1)\n",
        "    predicts.append(accuracy_score(label, y))\n",
        "\n",
        "    # calculando loss\n",
        "    loss = criterio(output, imagem)\n",
        "\n",
        "    # update running test loss\n",
        "    test_loss += loss.item()\n",
        "\n",
        "\n",
        "  test_loss = test_loss/len(test_loader)\n",
        "  end = time.time()\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    save_decod_img(imagem.cpu().data, output.cpu().data, epoch, name)\n",
        "\n",
        "  print('########## Test ##########')\n",
        "\n",
        "  \n",
        "  print(\"Test Loss: {:.6f}\\nAcurácia do Isolation Forest: {:.3f}\\t {} Outliers, {} Inliers\\n\".format(test_loss, (sum(predicts)/len(predicts)), outliers, inliers))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rXPlSNFijQU"
      },
      "source": [
        "## Plot Treino x Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "nUMrkYR5iiqC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "68ceb2c6-71c4-4121-cb5e-1584f9abd45b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        " plt.plot(train_losses, label='Train')\n",
        " plt.plot(val_losses, label='Test')\n",
        " plt.legend(loc=\"upper right\")\n",
        " plt.ylabel('Loss')\n",
        " plt.xlabel('Epochs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "HtWFdXgOA1N6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "30103c2e-3d08-46de-b259-e87b3c531687"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbQklEQVR4nO3de3RV5b3u8e8DKHjl1qgUpKEVpdwSMIi7VKtFxJ5dtYIt9HIAt0rt8bK3PXqkQ8+WInaoZR8cVk9trFZsFfBSleqoFq2oe9taEqRVVAy3DiLUIiCCHq7+zh9rki7jClnMZGUl5PmMscaa853vmuv3EkaezPmuNaciAjMzs/3VodgFmJlZ2+QAMTOzVBwgZmaWigPEzMxScYCYmVkqnYpdQEv61Kc+FaWlpcUuw8ysTamurn43Ikrqt7erACktLaWqqqrYZZiZtSmS/pqr3aewzMwsFQeImZml4gAxM7NU2tUciNmBateuXdTW1rJ9+/Zil2JtWJcuXejTpw8HHXRQXv0dIGYHgNraWo444ghKS0uRVOxyrA2KCDZu3EhtbS39+vXL6zU+hWV2ANi+fTs9e/Z0eFhqkujZs+d+HcU6QMwOEA4Pa6r9/T/kADEzs1QcIGbWZBs3bqS8vJzy8nKOOeYYevfuXbe+c+fORl+/aNEiXnrppZzb7r33XkpKShg2bBj9+/dn7NixDfbN9thjj/H666/v91j2Zc2aNTzwwAP77HPrrbfSpUsXtmzZ0qzv3Ro5QMysyXr27MnSpUtZunQpl1xyCVdeeWXd+sEHH9zo6/cVIAATJkzglVdeoaamhmnTpjFu3DjeeOONfe6zWAEyd+5cRowYwa9//etmfe9sEcFHH31UsP3nywFiZgVRXV3Nl770JU488UTGjh3L+vXrAbjtttsYOHAgQ4cOZeLEiaxZs4Y777yT2bNnU15ezosvvrjP/Z5++ulMnTqVyspKAO666y5GjBhBWVkZ48eP58MPP+Sll15iwYIFXH311ZSXl7Ny5cqc/QAeeughBg8eTFlZGaeeeioAe/bs4eqrr2bEiBEMHTqUn/3sZwBMmzaNF198kfLycmbPnv2J2lauXMm2bduYOXMmc+fOrWvftm0bF1xwAUOGDGHo0KE88sgjADz11FMMHz6csrIyRo8eDcD06dOZNWtW3WsHDx7MmjVrWLNmDSeccAKTJk1i8ODBrF27lu9973tUVFQwaNAgrr/++rrXLF68mC984QuUlZVx0kknsXXrVk499VSWLl1a1+eLX/wif/7zn/P8aebmj/GaHWB++JtlvL7u/Wbd58BPH8n1Zw/Ku39EcPnll/P4449TUlLC/Pnzufbaa7nnnnu46aabWL16NZ07d+a9996jW7duXHLJJRx++OFcddVVee1/+PDhdb/Ux40bx8UXXwzAddddx913383ll1/OOeecw1e/+lXOP/98ALp165az34wZM3j66afp3bs37733HgB33303Xbt2ZfHixezYsYNRo0Zx5plnctNNNzFr1iyeeOKJnHXNmzePiRMncsopp7B8+XLeeecdjj76aG644Qa6du3Kq6++CsDmzZvZsGEDF198MS+88AL9+vVj06ZNjY67pqaGOXPmcPLJJwNw44030qNHD/bs2cPo0aP5y1/+woABA5gwYQLz589nxIgRvP/++xxyyCFceOGF3Hvvvdx666289dZbbN++nbKysrz+vRviIxAza3Y7duzgtddeY8yYMZSXlzNz5kxqa2sBGDp0KN/+9rf51a9+RadO6f6GjYi65ddee41TTjmFIUOGcP/997Ns2bKcr2mo36hRo5gyZQp33XUXe/bsAeB3v/sd9913H+Xl5YwcOZKNGzdSU1PTaF1z585l4sSJdOjQgfHjx/PQQw8B8Mwzz3DppZfW9evevTt//OMfOfXUU+u+c9GjR49G9/+Zz3ymLjwAHnzwQYYPH86wYcNYtmwZr7/+OsuXL6dXr16MGDECgCOPPJJOnTrx9a9/nSeeeIJdu3Zxzz33MGXKlEbfrzE+AjE7wOzPkUKhRASDBg3iD3/4wye2Pfnkk7zwwgv85je/4cYbb6z7q3x/vPLKK3z+858HYMqUKTz22GOUlZVx7733smjRopyvaajfnXfeycsvv8yTTz7JiSeeSHV1NRHBT37yE8aOHfuxfTS0b4BXX32VmpoaxowZA8DOnTvp168fl1122X6NrVOnTh+b38j+XsZhhx1Wt7x69WpmzZrF4sWL6d69O1OmTNnndzgOPfRQxowZw+OPP86DDz5IdXX1ftWVi49AzKzZde7cmQ0bNtQFyK5du1i2bBkfffQRa9eu5fTTT+fmm29my5YtbNu2jSOOOIKtW7fmte/nn3+eysrKutNRW7dupVevXuzatYv777+/rl/9fTbUb+XKlYwcOZIZM2ZQUlLC2rVrGTt2LD/96U/ZtWsXAG+99RYffPDBPuucO3cu06dPr5uvWLduHevWreOvf/0rY8aM4Y477qjru3nzZk4++WReeOEFVq9eDVB3Cqu0tJQlS5YAsGTJkrrt9b3//vscdthhdO3alXfeeYff/va3AJxwwgmsX7+exYsX14179+7dAFx00UVcccUVjBgxgu7du+f1770vDhAza3YdOnTg4Ycf5pprrqGsrIzy8nJeeukl9uzZw3e+8x2GDBnCsGHDuOKKK+jWrRtnn302jz76aIOT6PPnz6e8vJzjjz+eH/3oRzzyyCN1RyA33HADI0eOZNSoUQwYMKDuNRMnTuTHP/4xw4YNY+XKlQ32u/rqqxkyZAiDBw+um3i+6KKLGDhwIMOHD2fw4MF897vfZffu3QwdOpSOHTtSVlb2iUn0efPmcd55532s7bzzzmPevHlcd911bN68uW6y/rnnnqOkpITKykrGjRtHWVkZEyZMAGD8+PFs2rSJQYMGcfvtt3P88cfn/DcuKytj2LBhDBgwgG9961uMGjUKgIMPPpj58+dz+eWXU1ZWxpgxY+qOTE488USOPPJILrjggv39keak7HOJB7qKiorwDaXsQPTGG2/U/UI1a8i6des47bTTePPNN+nQIffxQ67/S5KqI6Kifl8fgZiZtQP33XcfI0eO5MYbb2wwPPaXJ9HNzNqBSZMmMWnSpGbdp49AzA4Q7el0tBXG/v4fcoCYHQC6dOnCxo0bHSKW2t77gXTp0iXv1/gUltkBoE+fPtTW1rJhw4Zil2Jt2N47EubLAWJ2ADjooIPyvoucWXPxKSwzM0vFAWJmZqkUNUAknSVpuaQVkqbl2N5Z0vxk+8uSSutt7ytpm6T8LuFpZmbNpmgBIqkjcAfwFWAg8E1JA+t1uxDYHBHHAbOBm+tt/z/Abwtdq5mZfVIxj0BOAlZExKqI2AnMA86t1+dcYE6y/DAwWsld3yV9DVgN5L52s5mZFVQxA6Q3sDZrvTZpy9knInYDW4Cekg4HrgF+2NibSJoqqUpSlT/iaGbWfNrqJPp0YHZEbGusY0RURkRFRFSUlJQUvjIzs3aimN8DeRs4Nmu9T9KWq0+tpE5AV2AjMBI4X9ItQDfgI0nbI+L2wpdtZmZQ3ABZDPSX1I9MUEwEvlWvzwJgMvAH4Hzg95G5VsMpeztImg5sc3iYmbWsogVIROyWdBnwNNARuCcilkmaAVRFxALgbuCXklYAm8iEjJmZtQK+oZSZme2TbyhlZmbNygFiZmapOEDMzCwVB4iZmaXiADEzs1QcIGZmlooDxMzMUnGAmJlZKg4QMzNLxQFiZmapOEDMzCwVB4iZmaXiADEzs1QcIGZmlooDxMzMUnGAmJlZKg4QMzNLxQFiZmapOEDMzCwVB4iZmaXiADEzs1QcIGZmlooDxMzMUnGAmJlZKg4QMzNLxQFiZmapOEDMzCwVB4iZmaXiADEzs1QcIGZmlkpRA0TSWZKWS1ohaVqO7Z0lzU+2vyypNGkfI6la0qvJ85dbunYzs/auaAEiqSNwB/AVYCDwTUkD63W7ENgcEccBs4Gbk/Z3gbMjYggwGfhly1RtZmZ7FfMI5CRgRUSsioidwDzg3Hp9zgXmJMsPA6MlKSJeiYh1Sfsy4BBJnVukajMzA4obIL2BtVnrtUlbzj4RsRvYAvSs12c8sCQidhSoTjMzy6FTsQtoCkmDyJzWOnMffaYCUwH69u3bQpWZmR34inkE8jZwbNZ6n6QtZx9JnYCuwMZkvQ/wKDApIlY29CYRURkRFRFRUVJS0ozlm5m1b8UMkMVAf0n9JB0MTAQW1OuzgMwkOcD5wO8jIiR1A54EpkXEf7VYxWZmVqdoAZLMaVwGPA28ATwYEcskzZB0TtLtbqCnpBXA94G9H/W9DDgO+HdJS5PHUS08BDOzdk0RUewaWkxFRUVUVVUVuwwzszZFUnVEVNRv9zfRzcwsFQeImZml4gAxM7NUHCBmZpaKA8TMzFJxgJiZWSoOEDMzS8UBYmZmqThAzMwsFQeImZml4gAxM7NUHCBmZpaKA8TMzFJxgJiZWSoOEDMzS8UBYmZmqeQVIJK+KOmCZLlEUr/ClmVmZq1dowEi6XrgGuAHSdNBwK8KWZSZmbV++RyBnAecA3wAEBHrgCMKWZSZmbV++QTIzsjcOD0AJB1W2JLMzKwtyCdAHpT0M6CbpIuBZ4C7CluWmZm1dp0a6xARsySNAd4HTgD+PSIWFrwyMzNr1RoNEIAkMBwaZmZWp9EAkbSVZP4jyxagCvifEbGqEIWZmVnrls8RyK1ALfAAIGAi8DlgCXAPcFqhijMzs9Yrn0n0cyLiZxGxNSLej4hKYGxEzAe6F7g+MzNrpfIJkA8lfUNSh+TxDWB7sq3+qS0zM2sn8gmQbwP/Hfg78E6y/B1JhwCXFbA2MzNrxfL5GO8q4OwGNv9n85ZjZmZtRT6fwuoCXAgMArrsbY+IfylgXWZm1srlcwrrl8AxwFjgeaAPsLWQRZmZWeuXT4AcFxH/G/ggIuYA/wyMbI43l3SWpOWSVkialmN7Z0nzk+0vSyrN2vaDpH25pLHNUY+ZmeUvnwDZlTy/J2kw0BU4qqlvLKkjcAfwFWAg8E1JA+t1uxDYHBHHAbOBm5PXDiTzfZRBwFnA/032Z2ZmLSSfAKmU1B24DlgAvE7yi7yJTgJWRMSqiNgJzAPOrdfnXGBOsvwwMFqSkvZ5EbEjIlYDK5L9mZlZC9nnJLqkDsD7EbEZeAH4bDO+d29gbdZ6LZ88NVbXJyJ2S9oC9Eza/1jvtb1zvYmkqcBUgL59+zZL4WZm1sgRSER8BPyvFqqlICKiMiIqIqKipKSk2OWYmR0w8jmF9YykqyQdK6nH3kczvPfbwLFZ632Stpx9JHUiM/+yMc/XmplZAeUTIBOAS8mcwqpOHlXN8N6Lgf6S+kk6mMyk+IJ6fRYAk5Pl84HfJ3dHXABMTD6l1Q/oD/ypGWoyM7M85fNN9H6FeONkTuMy4GmgI3BPRCyTNAOoiogFwN3ALyWtADaRCRmSfg+SmdDfDVwaEXsKUaeZmeWmzB/0++ggHQp8H+gbEVMl9QdOiIgnWqLA5lRRURFVVc1x8GRm1n5Iqo6Iivrt+ZzC+gWwE/hCsv42MLMZazMzszYonwD5XETcQvKFwoj4kMyNpczMrB3LJ0B2JpduDwBJnwN2FLQqMzNr9fK5pe104CngWEn3A6OAKQWsyczM2oB8PoX1O0nVwMlkTl39a0S8W/DKzMysVcvnfiC/AR4AFkTEB4UvyczM2oJ85kBmAacAr0t6WNL5yU2mzMysHcvnFNbzwPPJ5dK/DFwM3AMcWeDazMysFctnEp3kU1hnk7msyXDg3gLWZGZmbUCjp7CSS4a8Qebo43Yy16byzZvMzNq5fOZA7ga+QeY+6L8AfkgmUMzMrB1r8BSWpOOBbyaPd4H5ZK6ddXoL1WZmZq3YvuZA3gReBL4aESsAJF3ZIlWZmVmrt69TWOOA9cBzku6SNBpfA8vMzBINBkhEPBYRE4EBwHPAvwFHSfqppDNbqkAzM2udGp1Ej4gPIuKBiDibzK1jXwGuKXhlZmbWquXzKaw6EbE5IiojYnShCjIzs7ZhvwLEzMxsLweImZml4gAxM7NUHCBmZpaKA8TMzFJxgJiZWSoOEDMzS8UBYmZmqThAzMwsFQeImZml4gAxM7NUHCBmZpaKA8TMzFIpSoBI6iFpoaSa5Ll7A/0mJ31qJE1O2g6V9KSkNyUtk3RTy1ZvZmZQvCOQacCzEdEfeDZZ/xhJPYDrgZHAScD1WUEzKyIGAMOAUZK+0jJlm5nZXsUKkHOBOcnyHOBrOfqMBRZGxKaI2AwsBM6KiA8j4jmAiNgJLCFzoyszM2tBxQqQoyNifbL8N+DoHH16A2uz1muTtjqSugFnkzmKMTOzFtSpUDuW9AxwTI5N12avRERIihT77wTMBW6LiFX76DcVmArQt2/f/X0bMzNrQMECJCLOaGibpHck9YqI9ZJ6AX/P0e1t4LSs9T7Aoqz1SqAmIm5tpI7KpC8VFRX7HVRmZpZbsU5hLQAmJ8uTgcdz9HkaOFNS92Ty/MykDUkzga7Av7VArWZmlkOxAuQmYIykGuCMZB1JFZJ+DhARm4AbgMXJY0ZEbJLUh8xpsIHAEklLJV1UjEGYmbVnimg/Z3UqKiqiqqqq2GWYmbUpkqojoqJ+u7+JbmZmqThAzMwsFQeImZml4gAxM7NUHCBmZpaKA8TMzFJxgJiZWSoOEDMzS8UBYmZmqThAzMwsFQeImZml4gAxM7NUHCBmZpaKA8TMzFJxgJiZWSoOEDMzS8UBYmZmqThAzMwsFQeImZml4gAxM7NUHCBmZpaKA8TMzFJxgJiZWSoOEDMzS8UBYmZmqThAzMwsFQeImZml4gAxM7NUHCBmZpaKA8TMzFJxgJiZWSpFCRBJPSQtlFSTPHdvoN/kpE+NpMk5ti+Q9FrhKzYzs/qKdQQyDXg2IvoDzybrHyOpB3A9MBI4Cbg+O2gkjQO2tUy5ZmZWX7EC5FxgTrI8B/hajj5jgYURsSkiNgMLgbMAJB0OfB+Y2QK1mplZDsUKkKMjYn2y/Dfg6Bx9egNrs9ZrkzaAG4D/AD5s7I0kTZVUJalqw4YNTSjZzMyydSrUjiU9AxyTY9O12SsREZJiP/ZbDnwuIq6UVNpY/4ioBCoBKioq8n4fMzPbt4IFSESc0dA2Se9I6hUR6yX1Av6eo9vbwGlZ632ARcA/ARWS1pCp/yhJiyLiNMzMrMUU6xTWAmDvp6omA4/n6PM0cKak7snk+ZnA0xHx04j4dESUAl8E3nJ4mJm1vGIFyE3AGEk1wBnJOpIqJP0cICI2kZnrWJw8ZiRtZmbWCiii/UwLVFRURFVVVbHLMDNrUyRVR0RF/XZ/E93MzFJxgJiZWSoOEDMzS8UBYmZmqThAzMwsFQeImZml4gAxM7NUHCBmZpaKA8TMzFJxgJiZWSoOEDMzS8UBYmZmqThAzMwsFQeImZml4gAxM7NUHCBmZpaKA8TMzFJxgJiZWSoOEDMzS8UBYmZmqThAzMwsFQeImZml4gAxM7NUHCBmZpaKIqLYNbQYSRuAvxa7jv30KeDdYhfRwjzm9sFjbjs+ExEl9RvbVYC0RZKqIqKi2HW0JI+5ffCY2z6fwjIzs1QcIGZmlooDpPWrLHYBReAxtw8ecxvnORAzM0vFRyBmZpaKA8TMzFJxgLQCknpIWiipJnnu3kC/yUmfGkmTc2xfIOm1wlfcdE0Zs6RDJT0p6U1JyyTd1LLV7x9JZ0laLmmFpGk5tneWND/Z/rKk0qxtP0jal0sa25J1N0XaMUsaI6la0qvJ85dbuvY0mvIzTrb3lbRN0lUtVXOziAg/ivwAbgGmJcvTgJtz9OkBrEqeuyfL3bO2jwMeAF4r9ngKPWbgUOD0pM/BwIvAV4o9pgbG2RFYCXw2qfXPwMB6ff4HcGeyPBGYnywPTPp3Bvol++lY7DEVeMzDgE8ny4OBt4s9nkKON2v7w8BDwFXFHs/+PHwE0jqcC8xJlucAX8vRZyywMCI2RcRmYCFwFoCkw4HvAzNboNbmknrMEfFhRDwHEBE7gSVAnxaoOY2TgBURsSqpdR6ZsWfL/rd4GBgtSUn7vIjYERGrgRXJ/lq71GOOiFciYl3Svgw4RFLnFqk6vab8jJH0NWA1mfG2KQ6Q1uHoiFifLP8NODpHn97A2qz12qQN4AbgP4APC1Zh82vqmAGQ1A04G3i2EEU2g0bHkN0nInYDW4Ceeb62NWrKmLONB5ZExI4C1dlcUo83+ePvGuCHLVBns+tU7ALaC0nPAMfk2HRt9kpEhKS8P1stqRz4XERcWf+8arEVasxZ++8EzAVui4hV6aq01kjSIOBm4Mxi11Jg04HZEbEtOSBpUxwgLSQizmhom6R3JPWKiPWSegF/z9HtbeC0rPU+wCLgn4AKSWvI/DyPkrQoIk6jyAo45r0qgZqIuLUZyi2Ut4Fjs9b7JG25+tQmodgV2Jjna1ujpowZSX2AR4FJEbGy8OU2WVPGOxI4X9ItQDfgI0nbI+L2wpfdDIo9CeNHAPyYj08o35KjTw8y50m7J4/VQI96fUppO5PoTRozmfmeR4AOxR5LI+PsRGbyvx//mGAdVK/PpXx8gvXBZHkQH59EX0XbmERvypi7Jf3HFXscLTHeen2m08Ym0YtegB8BmXO/zwI1wDNZvyQrgJ9n9fsXMhOpK4ALcuynLQVI6jGT+QsvgDeApcnjomKPaR9j/W/AW2Q+qXNt0jYDOCdZ7kLmEzgrgD8Bn8167bXJ65bTSj9p1pxjBq4DPsj6uS4Fjir2eAr5M87aR5sLEF/KxMzMUvGnsMzMLBUHiJmZpeIAMTOzVBwgZmaWigPEzMxScYCYNZGkPZKWZj0+cTXWJuy7tK1cYdnaH38T3azp/l9ElBe7CLOW5iMQswKRtEbSLcm9Lf4k6bikvVTS7yX9RdKzkvom7UdLelTSn5PHF5JddZR0V3Lvk99JOiTpf4Wk15P9zCvSMK0dc4CYNd0h9U5hTcjatiUihgC3A3uv2fUTYE5EDAXuB25L2m8Dno+IMmA4/7i8d3/gjogYBLxH5iq1kLkEzLBkP5cUanBmDfE30c2aSNK2iDg8R/sa4MsRsUrSQcDfIqKnpHeBXhGxK2lfHxGfkrQB6BNZly9PrrC8MCL6J+vXAAdFxExJTwHbgMeAxyJiW4GHavYxPgIxK6xoYHl/ZN8PYw//mLv8Z+AOMkcri5OrvJq1GAeIWWFNyHr+Q7L8EpkrsgJ8m8wteSFzccnvAUjqKKlrQzuV1AE4NjJ3ZryGzOXBP3EUZFZI/ovFrOkOkbQ0a/2piNj7Ud7ukv5C5ijim0nb5cAvJF0NbAAuSNr/FaiUdCGZI43vAevJrSPwqyRkROamWu8124jM8uA5ELMCSeZAKiLi3WLXYlYIPoVlZmap+AjEzMxS8RGImZml4gAxM7NUHCBmZpaKA8TMzFJxgJiZWSr/Hy0t/gEpMHRKAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        " plt.plot(val_predicts, label='Test Dataset Accuracy')\n",
        " plt.legend(loc=\"upper right\")\n",
        " plt.ylabel('Average')\n",
        " plt.xlabel('Epochs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHoIUvBmirI9"
      },
      "source": [
        "## Plot da Imagem Original(normalizada) x Imagem Reconstruída via AutoEncoder Convolucional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "CNOb9zHIiohP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "0fb00ebf-2d62-4352-eb30-8084ad8403b2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-76f0cd9469b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# output is resized into a batch of iages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# use detach when it's an output that requires_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[50, 1, 120, 120]' is invalid for input of size 1280000"
          ]
        }
      ],
      "source": [
        "# obtain one batch of test images\n",
        "dataiter = iter(train_loader)\n",
        "images = dataiter.next()\n",
        "\n",
        "imagem = images.unsqueeze(1).float()\n",
        "imagem /= 255.0\n",
        "imagem = imagem.to(args['device'])\n",
        "\n",
        "# get sample outputs\n",
        "output = model(imagem)\n",
        "# prep images for display\n",
        "images = images.numpy()\n",
        "\n",
        "\n",
        "\n",
        "# output is resized into a batch of iages\n",
        "output = output.view(args['batch_size'], 1, 120, 120)\n",
        "# use detach when it's an output that requires_grad\n",
        "output = output.detach()#.numpy()\n",
        "\n",
        "\n",
        "\n",
        "# plot the first ten input images and then reconstructed images\n",
        "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    loss = criterio(output[idx], imagem[idx])\n",
        "    label = 'Loss value: {:.3f}'\n",
        "    ax.set_xlabel(label.format(loss) )\n",
        "    ax.set_title(\"Reconstructed Image\")\n",
        "    plt.imshow(output[idx].squeeze().cpu(), cmap='gray')\n",
        "    \n",
        "# plot the first ten input images and then reconstructed images\n",
        "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    loss = criterio(output[idx], imagem[idx])\n",
        "    label = 'Loss value: {:.3f}'\n",
        "    ax.set_xlabel(label.format(loss) )\n",
        "    ax.set_title(\"Original Image\")\n",
        "    plt.imshow(images[idx].squeeze(), cmap='gray')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogQCkTYUE9cY"
      },
      "outputs": [],
      "source": [
        "# obtain one batch of test images\n",
        "dataiter = iter(test_loader)\n",
        "images = dataiter.next()\n",
        "\n",
        "imagem = images.unsqueeze(1).float()\n",
        "imagem /= 255.0\n",
        "imagem = imagem.to(args['device'])\n",
        "\n",
        "# get sample outputs\n",
        "output = model(imagem)\n",
        "# prep images for display\n",
        "images = images.numpy()\n",
        "\n",
        "\n",
        "\n",
        "# output is resized into a batch of iages\n",
        "output = output.view(args['batch_size'], 1, 120, 120)\n",
        "# use detach when it's an output that requires_grad\n",
        "output = output.detach()#.numpy()\n",
        "\n",
        "\n",
        "\n",
        "# plot the first ten input images and then reconstructed images\n",
        "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    loss = criterio(output[idx], imagem[idx])\n",
        "    label = 'Loss value: {:.3f}'\n",
        "    ax.set_xlabel(label.format(loss) )\n",
        "    ax.set_title(\"Reconstructed Image\")\n",
        "    plt.imshow(output[idx].squeeze().cpu(), cmap='gray')\n",
        "    \n",
        "# plot the first ten input images and then reconstructed images\n",
        "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    loss = criterio(output[idx], imagem[idx])\n",
        "    label = 'Loss value: {:.3f}'\n",
        "    ax.set_xlabel(label.format(loss) )\n",
        "    ax.set_title(\"Original Image\")\n",
        "    plt.imshow(images[idx].squeeze(), cmap='gray')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Nezw53Hj-JA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "isolation_tcc.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnNdvbaxYqHuMR9MFPPbGs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}